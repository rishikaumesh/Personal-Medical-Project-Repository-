{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07590d8-e437-461f-b2ff-e3e17b630d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data_loaders.py\n",
    "\n",
    "# # Import necessary libraries\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# # Define transformations with data augmentation for training\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.RandomRotation(30),  # randomly rotate images up to 30 degrees\n",
    "#     transforms.RandomHorizontalFlip(),  # randomly flip images horizontally\n",
    "#     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # randomly shift images\n",
    "#     transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # simulate random zooming\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Define transformations for validation and test (no augmentation)\n",
    "# val_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Load the training dataset with augmentation\n",
    "# train_dataset = datasets.ImageFolder(root='/home/user/persistent/chest_xray/chest_xray/train', transform=train_transform)\n",
    "\n",
    "# # Calculate sample weights for the WeightedRandomSampler\n",
    "# class_counts = [1342, 3876]  # Number of Normal and Pneumonia images\n",
    "# class_weights = [1.0 / count for count in class_counts]\n",
    "# targets = [label for _, label in train_dataset]\n",
    "# sample_weights = [class_weights[label] for label in targets]\n",
    "\n",
    "# # Create the WeightedRandomSampler\n",
    "# sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# # Create DataLoader for training with the sampler\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=4)\n",
    "\n",
    "# # Load the validation dataset without augmentation\n",
    "# val_dataset = datasets.ImageFolder(root='/home/user/persistent/chest_xray/chest_xray/val', transform=val_transform)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# # Load the test dataset without augmentation\n",
    "# test_dataset = datasets.ImageFolder(root='/home/user/persistent/chest_xray/chest_xray/test', transform=val_transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# # Print dataset sizes\n",
    "# print(f'Number of images in training set: {len(train_dataset)}')\n",
    "# print(f'Number of images in validation set: {len(val_dataset)}')\n",
    "# print(f'Number of images in test set: {len(test_dataset)}')\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"Data loaders for training, validation, and testing with data augmentation and class balancing are set up and ready for use.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d581ab4-6877-4c83-94a1-e42e820ed549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data_loaders_and_training.py\n",
    "\n",
    "# # Import necessary libraries\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, WeightedRandomSampler, Subset\n",
    "# from torchvision import datasets, transforms\n",
    "# import nbimporter\n",
    "# from model import PneumoniaDetectionCNN\n",
    "# from sklearn.model_selection import KFold\n",
    "# import matplotlib.pyplot as plt\n",
    "# import csv\n",
    "\n",
    "\n",
    "# def load_data():\n",
    "#     # Define transformations with data augmentation for training\n",
    "#     train_transform = transforms.Compose([\n",
    "#         transforms.Resize((224, 224)),\n",
    "#         transforms.RandomRotation(30),  # randomly rotate images up to 30 degrees\n",
    "#         transforms.RandomHorizontalFlip(),  # randomly flip images horizontally\n",
    "#         transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # randomly shift images\n",
    "#         transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # simulate random zooming\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "\n",
    "#     # Define transformations for validation and test (no augmentation)\n",
    "#     val_transform = transforms.Compose([\n",
    "#         transforms.Resize((224, 224)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "\n",
    "#     # Load the training dataset with augmentation\n",
    "#     train_dataset = datasets.ImageFolder(root='/home/user/persistent/chest_xray/chest_xray/train', transform=train_transform)\n",
    "\n",
    "#     # Calculate sample weights for the WeightedRandomSampler\n",
    "#     class_counts = [1342, 3876]  # Number of Normal and Pneumonia images\n",
    "#     class_weights = [1.0 / count for count in class_counts]\n",
    "#     targets = [label for _, label in train_dataset]\n",
    "#     sample_weights = [class_weights[label] for label in targets]\n",
    "\n",
    "#     # Create the WeightedRandomSampler\n",
    "#     sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "#     # Create DataLoader for training with the sampler\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=4)\n",
    "\n",
    "#     # Load the validation dataset without augmentation\n",
    "#     val_dataset = datasets.ImageFolder(root='/home/user/persistent/chest_xray/chest_xray/val', transform=val_transform)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "#     # Load the test dataset without augmentation\n",
    "#     test_dataset = datasets.ImageFolder(root='/home/user/persistent/chest_xray/chest_xray/test', transform=val_transform)\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "#     # Print dataset sizes\n",
    "#     print(f'Number of images in training set: {len(train_dataset)}')\n",
    "#     print(f'Number of images in validation set: {len(val_dataset)}')\n",
    "#     print(f'Number of images in test set: {len(test_dataset)}')\n",
    "\n",
    "#     print(\"Data loaders for training, validation, and testing with data augmentation and class balancing are set up and ready for use.\")\n",
    "\n",
    "#     return train_dataset, train_loader, val_loader, test_loader\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Call load_data function\n",
    "#     train_dataset, train_loader, val_loader, test_loader = load_data()\n",
    "#     print(\"Data loading completed. Proceeding to training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b829e1d2-84ba-4e46-ab7b-ca76e648da68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in training set: 5216\n",
      "Number of images in validation set: 16\n",
      "Number of images in test set: 624\n",
      "Data loaders for training, validation, and testing with data augmentation and class balancing are set up and ready for use.\n",
      "Data loading completed. Proceeding to training.\n"
     ]
    }
   ],
   "source": [
    "# data_loaders_and_training.py\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import nbimporter\n",
    "from model import PneumoniaDetectionCNN\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "def load_data():\n",
    "    # Set the image size\n",
    "    img_size = 224\n",
    "\n",
    "    # Define transformations for training with data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "        transforms.Resize((img_size, img_size)),      # Resize to specified image size\n",
    "        transforms.RandomRotation(30),                # randomly rotate images up to 30 degrees\n",
    "        transforms.RandomHorizontalFlip(),            # randomly flip images horizontally\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # randomly shift images\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),  # simulate random zooming\n",
    "        transforms.ToTensor(),                        # Convert to tensor (scales data to [0, 1])\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])   # Normalize to match x / 255 scaling\n",
    "    ])\n",
    "\n",
    "    # Define transformations for validation and test (no augmentation)\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "        transforms.Resize((img_size, img_size)),      # Resize to specified image size\n",
    "        transforms.ToTensor(),                        # Convert to tensor (scales data to [0, 1])\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])   # Normalize to match x / 255 scaling\n",
    "    ])\n",
    "\n",
    "    # Load the training dataset with augmentation\n",
    "    train_dataset = datasets.ImageFolder(root='/home/user/persistent/chest_xray/chest_xray/train', transform=train_transform)\n",
    "\n",
    "    # Calculate sample weights for the WeightedRandomSampler\n",
    "    class_counts = [1342, 3876]  # Number of Normal and Pneumonia images\n",
    "    class_weights = [1.0 / count for count in class_counts]\n",
    "    targets = [label for _, label in train_dataset]\n",
    "    sample_weights = [class_weights[label] for label in targets]\n",
    "\n",
    "    # Create the WeightedRandomSampler\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    # Create DataLoader for training with the sampler\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=4)\n",
    "\n",
    "    # Load the validation dataset without augmentation\n",
    "    val_dataset = datasets.ImageFolder(root='/home/user/persistent/chest_xray/chest_xray/val', transform=val_transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Load the test dataset without augmentation\n",
    "    test_dataset = datasets.ImageFolder(root='/home/user/persistent/chest_xray/chest_xray/test', transform=val_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Print dataset sizes\n",
    "    print(f'Number of images in training set: {len(train_dataset)}')\n",
    "    print(f'Number of images in validation set: {len(val_dataset)}')\n",
    "    print(f'Number of images in test set: {len(test_dataset)}')\n",
    "\n",
    "    print(\"Data loaders for training, validation, and testing with data augmentation and class balancing are set up and ready for use.\")\n",
    "\n",
    "    return train_dataset, train_loader, val_loader, test_loader\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Call load_data function\n",
    "    train_dataset, train_loader, val_loader, test_loader = load_data()\n",
    "    print(\"Data loading completed. Proceeding to training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe80fefd-0557-4fa3-85de-cae625a48190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in training set: 5216\n",
      "Number of images in validation set: 16\n",
      "Number of images in test set: 624\n",
      "Data loaders for training, validation, and testing with data augmentation and class balancing are set up and ready for use.\n",
      "Data loading completed. Proceeding to save transformed images.\n",
      "Saving transformed training images...\n",
      "Saving transformed validation images...\n",
      "Saving transformed test images...\n",
      "All transformed images have been saved.\n"
     ]
    }
   ],
   "source": [
    "# data_loaders_and_training.py\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import nbimporter\n",
    "from model import PneumoniaDetectionCNN\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "def load_data():\n",
    "    # Set the image size\n",
    "    img_size = 224\n",
    "\n",
    "    # Define transformations for training with data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "        transforms.Resize((img_size, img_size)),      # Resize to specified image size\n",
    "        transforms.RandomRotation(30),                # randomly rotate images up to 30 degrees\n",
    "        transforms.RandomHorizontalFlip(),            # randomly flip images horizontally\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # randomly shift images\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),  # simulate random zooming\n",
    "        transforms.ToTensor(),                        # Convert to tensor (scales data to [0, 1])\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])   # Normalize to match x / 255 scaling\n",
    "    ])\n",
    "\n",
    "    # Define transformations for validation and test (no augmentation)\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "        transforms.Resize((img_size, img_size)),      # Resize to specified image size\n",
    "        transforms.ToTensor(),                        # Convert to tensor (scales data to [0, 1])\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])   # Normalize to match x / 255 scaling\n",
    "    ])\n",
    "\n",
    "    # Load the training dataset with augmentation\n",
    "    train_dataset = datasets.ImageFolder(root='/home/user/persistent/chest_xray/chest_xray/train', transform=train_transform)\n",
    "\n",
    "    # Calculate sample weights for the WeightedRandomSampler\n",
    "    class_counts = [1342, 3876]  # Number of Normal and Pneumonia images\n",
    "    class_weights = [1.0 / count for count in class_counts]\n",
    "    targets = [label for _, label in train_dataset]\n",
    "    sample_weights = [class_weights[label] for label in targets]\n",
    "\n",
    "    # Create the WeightedRandomSampler\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    # Create DataLoader for training with the sampler\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=4)\n",
    "\n",
    "    # Load the validation dataset without augmentation\n",
    "    val_dataset = datasets.ImageFolder(root='/home/user/persistent/chest_xray/chest_xray/val', transform=val_transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Load the test dataset without augmentation\n",
    "    test_dataset = datasets.ImageFolder(root='/home/user/persistent/chest_xray/chest_xray/test', transform=val_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Print dataset sizes\n",
    "    print(f'Number of images in training set: {len(train_dataset)}')\n",
    "    print(f'Number of images in validation set: {len(val_dataset)}')\n",
    "    print(f'Number of images in test set: {len(test_dataset)}')\n",
    "\n",
    "    print(\"Data loaders for training, validation, and testing with data augmentation and class balancing are set up and ready for use.\")\n",
    "\n",
    "    return train_dataset, train_loader, val_loader, test_loader\n",
    "\n",
    "def save_transformed_images(loader, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for i, (images, labels) in enumerate(loader):\n",
    "        for j in range(images.size(0)):\n",
    "            img = ToPILImage()(images[j])\n",
    "            label_dir = os.path.join(output_dir, str(labels[j].item()))\n",
    "            if not os.path.exists(label_dir):\n",
    "                os.makedirs(label_dir)\n",
    "            img.save(os.path.join(label_dir, f'image_{i * loader.batch_size + j}.png'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Call load_data function\n",
    "    train_dataset, train_loader, val_loader, test_loader = load_data()\n",
    "    print(\"Data loading completed. Proceeding to save transformed images.\")\n",
    "\n",
    "    # Define output directories for saving transformed images\n",
    "    train_output_dir = '/home/user/persistent/chest_xray/chest_xray/augmented/train'\n",
    "    val_output_dir = '/home/user/persistent/chest_xray/chest_xray/augmented/val'\n",
    "    test_output_dir = '/home/user/persistent/chest_xray/chest_xray/augmented/test'\n",
    "\n",
    "    # Save transformed images to the output directories\n",
    "    print(\"Saving transformed training images...\")\n",
    "    save_transformed_images(train_loader, train_output_dir)\n",
    "\n",
    "    print(\"Saving transformed validation images...\")\n",
    "    save_transformed_images(val_loader, val_output_dir)\n",
    "\n",
    "    print(\"Saving transformed test images...\")\n",
    "    save_transformed_images(test_loader, test_output_dir)\n",
    "\n",
    "    print(\"All transformed images have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3678eeb6-18f2-4009-819e-756766f8ab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in training set: 5216\n",
      "Number of images in validation set: 16\n",
      "Number of images in test set: 624\n",
      "\n",
      "Fold 1/5\n",
      "Epoch [1/25], Loss: 49.4347\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Best model for this fold saved!\n",
      "Epoch [2/25], Loss: 50.5725\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [3/25], Loss: 50.4532\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [4/25], Loss: 50.4930\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [5/25], Loss: 50.4930\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [6/25], Loss: 50.4532\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [7/25], Loss: 50.5328\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [8/25], Loss: 50.5328\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [9/25], Loss: 50.4930\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [10/25], Loss: 50.5328\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [11/25], Loss: 50.4930\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [12/25], Loss: 50.5328\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [13/25], Loss: 50.3737\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [14/25], Loss: 50.3737\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [15/25], Loss: 50.3737\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [16/25], Loss: 50.5725\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [17/25], Loss: 50.4135\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [18/25], Loss: 50.3737\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [19/25], Loss: 50.4930\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [20/25], Loss: 50.4532\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [21/25], Loss: 50.5328\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [22/25], Loss: 50.4930\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [23/25], Loss: 50.3340\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [24/25], Loss: 50.5328\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "Epoch [25/25], Loss: 50.4930\n",
      "Validation Loss: 51.7045, Validation Accuracy: 47.70%\n",
      "\n",
      "Fold 2/5\n",
      "Epoch [1/25], Loss: 50.0385\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Best model for this fold saved!\n",
      "Epoch [2/25], Loss: 50.4954\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [3/25], Loss: 50.2124\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [4/25], Loss: 50.4954\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [5/25], Loss: 50.5652\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [6/25], Loss: 50.3909\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [7/25], Loss: 50.6349\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [8/25], Loss: 50.6000\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [9/25], Loss: 50.4954\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [10/25], Loss: 50.5303\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [11/25], Loss: 50.6000\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [12/25], Loss: 50.4606\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [13/25], Loss: 50.4606\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [14/25], Loss: 50.4954\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [15/25], Loss: 50.5303\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [16/25], Loss: 50.4606\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [17/25], Loss: 50.5303\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [18/25], Loss: 50.4606\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [19/25], Loss: 50.5652\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [20/25], Loss: 50.5652\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [21/25], Loss: 50.3909\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [22/25], Loss: 50.4954\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [23/25], Loss: 50.5303\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [24/25], Loss: 50.5652\n",
      "Validation Loss: 51.4205, Validation Accuracy: 47.94%\n",
      "Epoch [24/25], Loss: 48.6696\n",
      "Validation Loss: 48.5428, Validation Accuracy: 48.90%\n",
      "Epoch [25/25], Loss: 48.6267\n",
      "Validation Loss: 48.5289, Validation Accuracy: 48.90%\n",
      "\n",
      "Fold 4/5\n",
      "Epoch [1/25], Loss: 48.7648\n",
      "Validation Loss: 35.8562, Validation Accuracy: 53.21%\n",
      "Best model for this fold saved!\n",
      "Epoch [2/25], Loss: 49.4206\n",
      "Validation Loss: 35.8789, Validation Accuracy: 53.21%\n",
      "Epoch [3/25], Loss: 49.3592\n",
      "Validation Loss: 35.7621, Validation Accuracy: 53.21%\n",
      "Epoch [4/25], Loss: 49.4918\n",
      "Validation Loss: 35.8400, Validation Accuracy: 53.21%\n",
      "Epoch [5/25], Loss: 49.3626\n",
      "Validation Loss: 36.0878, Validation Accuracy: 53.21%\n",
      "Epoch [6/25], Loss: 49.2772\n",
      "Validation Loss: 35.7455, Validation Accuracy: 53.21%\n",
      "Epoch [7/25], Loss: 49.3032\n",
      "Validation Loss: 35.8266, Validation Accuracy: 53.21%\n",
      "Epoch [8/25], Loss: 49.2124\n",
      "Validation Loss: 35.3751, Validation Accuracy: 53.21%\n",
      "Epoch [9/25], Loss: 49.1630\n",
      "Validation Loss: 34.9962, Validation Accuracy: 53.21%\n",
      "Epoch [10/25], Loss: 49.1280\n",
      "Validation Loss: 35.1536, Validation Accuracy: 53.21%\n",
      "Epoch [11/25], Loss: 49.2798\n",
      "Validation Loss: 35.4467, Validation Accuracy: 53.21%\n",
      "Epoch [12/25], Loss: 49.2450\n",
      "Validation Loss: 35.3493, Validation Accuracy: 53.21%\n",
      "Epoch [13/25], Loss: 48.3769\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "Epoch [14/25], Loss: 50.1395\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "Epoch [15/25], Loss: 50.1046\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "Epoch [16/25], Loss: 50.2441\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "Epoch [17/25], Loss: 50.2092\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "Epoch [18/25], Loss: 50.2789\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "Epoch [19/25], Loss: 50.3138\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "Epoch [20/25], Loss: 50.1046\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "Epoch [21/25], Loss: 50.3138\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "Epoch [22/25], Loss: 50.1395\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "Epoch [23/25], Loss: 50.2092\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "Epoch [24/25], Loss: 50.2441\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "Epoch [25/25], Loss: 50.1395\n",
      "Validation Loss: 52.5568, Validation Accuracy: 46.79%\n",
      "\n",
      "Fold 5/5\n",
      "Epoch [1/25], Loss: 48.1469\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Best model for this fold saved!\n",
      "Epoch [2/25], Loss: 48.3694\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [3/25], Loss: 48.3687\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [4/25], Loss: 48.4421\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [5/25], Loss: 48.4072\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [6/25], Loss: 48.3026\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [7/25], Loss: 48.2678\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [8/25], Loss: 48.4072\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [9/25], Loss: 48.4072\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [10/25], Loss: 48.4072\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [11/25], Loss: 48.3724\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [12/25], Loss: 48.4770\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [13/25], Loss: 48.2678\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [14/25], Loss: 48.5815\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [15/25], Loss: 48.4027\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [16/25], Loss: 48.4072\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [17/25], Loss: 48.3724\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [18/25], Loss: 48.3026\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [19/25], Loss: 48.4072\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [20/25], Loss: 48.3724\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [21/25], Loss: 48.4072\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [22/25], Loss: 48.3026\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [23/25], Loss: 48.3375\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [24/25], Loss: 48.4770\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "Epoch [25/25], Loss: 48.3026\n",
      "Validation Loss: 52.9356, Validation Accuracy: 47.65%\n",
      "\n",
      "Average Validation Accuracy across 5 folds: 49.08%\n",
      "Average Validation Loss across 5 folds: 47.7926\n",
      "K-Fold Cross-Validation complete and results saved.\n"
     ]
    }
   ],
   "source": [
    "# data_loaders_and_training.py\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import nbimporter\n",
    "from model import PneumoniaDetectionCNN\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "def train_model(device):\n",
    "    # Paths to the transformed data directories\n",
    "    train_data_path = '/home/user/persistent/chest_xray/chest_xray/augmented/train'\n",
    "    val_data_path = '/home/user/persistent/chest_xray/chest_xray/augmented/val'\n",
    "    test_data_path = '/home/user/persistent/chest_xray/chest_xray/augmented/test'\n",
    "\n",
    "    # Define transformations (already transformed, just converting to tensor and normalizing)\n",
    "    base_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # Ensure grayscale consistency\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])   # Normalize as per the previous transformation\n",
    "    ])\n",
    "\n",
    "    # Load the training, validation, and test datasets from transformed directories\n",
    "    train_dataset = datasets.ImageFolder(root=train_data_path, transform=base_transform)\n",
    "    val_dataset = datasets.ImageFolder(root=val_data_path, transform=base_transform)\n",
    "    test_dataset = datasets.ImageFolder(root=test_data_path, transform=base_transform)\n",
    "\n",
    "    # Create DataLoader objects\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Print dataset sizes\n",
    "    print(f'Number of images in training set: {len(train_dataset)}')\n",
    "    print(f'Number of images in validation set: {len(val_dataset)}')\n",
    "    print(f'Number of images in test set: {len(test_dataset)}')\n",
    "\n",
    "    # Define the number of folds for K-Fold Cross-Validation\n",
    "    k_folds = 5\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store average results across all folds\n",
    "    fold_accuracies = []\n",
    "    fold_val_losses = []\n",
    "\n",
    "    # Iterate over each fold\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "        print(f'\\nFold {fold + 1}/{k_folds}')\n",
    "        \n",
    "        # Create subsets for this fold\n",
    "        train_sub = Subset(train_dataset, train_idx)\n",
    "        val_sub = Subset(train_dataset, val_idx)\n",
    "        \n",
    "        # Create DataLoader objects for the current fold\n",
    "        train_loader = DataLoader(train_sub, batch_size=32, shuffle=True, num_workers=4)\n",
    "        val_loader = DataLoader(val_sub, batch_size=32, shuffle=False, num_workers=4)\n",
    "        \n",
    "        # Initialize the model\n",
    "        model = PneumoniaDetectionCNN().to(device)\n",
    "        criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Training parameters\n",
    "        num_epochs = 25\n",
    "        best_fold_accuracy = 0.0\n",
    "        \n",
    "        # Training loop for the current fold\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "                \n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            train_losses.append(running_loss / len(train_loader))\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_losses[-1]:.4f}')\n",
    "            \n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "                    outputs = model(images)\n",
    "                    val_loss += criterion(outputs, labels).item()\n",
    "                    predicted = (outputs > 0.5).int()\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels.int()).sum().item()\n",
    "            \n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            val_accuracy = 100 * correct / total\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            print(f'Validation Loss: {val_losses[-1]:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "            \n",
    "            # Save the best model for this fold\n",
    "            if val_accuracy > best_fold_accuracy:\n",
    "                best_fold_accuracy = val_accuracy\n",
    "                torch.save(model.state_dict(), f'best_model_fold_{fold + 1}.pth')\n",
    "                print('Best model for this fold saved!')\n",
    "        \n",
    "        fold_accuracies.append(best_fold_accuracy)\n",
    "        fold_val_losses.append(min(val_losses))\n",
    "\n",
    "    # Calculate average results across all folds\n",
    "    average_accuracy = sum(fold_accuracies) / k_folds\n",
    "    average_val_loss = sum(fold_val_losses) / k_folds\n",
    "\n",
    "    print(f'\\nAverage Validation Accuracy across {k_folds} folds: {average_accuracy:.2f}%')\n",
    "    print(f'Average Validation Loss across {k_folds} folds: {average_val_loss:.4f}')\n",
    "\n",
    "    # Save overall results to a CSV file\n",
    "    with open('kfold_results.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['fold', 'val_accuracy', 'val_loss']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for fold in range(k_folds):\n",
    "            writer.writerow({'fold': fold + 1, 'val_accuracy': fold_accuracies[fold], 'val_loss': fold_val_losses[fold]})\n",
    "\n",
    "    print('K-Fold Cross-Validation complete and results saved.')\n",
    "\n",
    "# Direct function call for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_model(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b311be1c-f988-4516-801e-6ae04281565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# Read the training metrics from the CSV file\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Replace 'training_metrics.csv' with your CSV file if you saved the data during training\n",
    "with open('kfold_results.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        val_losses.append(float(row['val_loss']))\n",
    "        val_accuracies.append(float(row['val_accuracy']))\n",
    "\n",
    "# Generate the plot for losses\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss Across Folds')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Generate the plot for accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy', color='orange')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy Across Folds')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adeee73-6bca-4700-9d54-f3040fee4ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loaders_and_training.py\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import nbimporter\n",
    "from model import PneumoniaDetectionCNN\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "def train_model(device):\n",
    "    # Paths to the transformed data directories\n",
    "    train_data_path = '/home/user/persistent/chest_xray/chest_xray/augmented/train'\n",
    "    val_data_path = '/home/user/persistent/chest_xray/chest_xray/augmented/val'\n",
    "    test_data_path = '/home/user/persistent/chest_xray/chest_xray/augmented/test'\n",
    "\n",
    "    # Define transformations (already transformed, just converting to tensor and normalizing)\n",
    "    base_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # Ensure grayscale consistency\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])   # Normalize as per the previous transformation\n",
    "    ])\n",
    "\n",
    "    # Load the training, validation, and test datasets from transformed directories\n",
    "    train_dataset = datasets.ImageFolder(root=train_data_path, transform=base_transform)\n",
    "    val_dataset = datasets.ImageFolder(root=val_data_path, transform=base_transform)\n",
    "    test_dataset = datasets.ImageFolder(root=test_data_path, transform=base_transform)\n",
    "\n",
    "    # Create DataLoader objects\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Print dataset sizes\n",
    "    print(f'Number of images in training set: {len(train_dataset)}')\n",
    "    print(f'Number of images in validation set: {len(val_dataset)}')\n",
    "    print(f'Number of images in test set: {len(test_dataset)}')\n",
    "\n",
    "    # Define the number of folds for K-Fold Cross-Validation\n",
    "    k_folds = 5\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store average results across all folds\n",
    "    fold_accuracies = []\n",
    "    fold_val_losses = []\n",
    "\n",
    "    # Iterate over each fold\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "        print(f'\\nFold {fold + 1}/{k_folds}')\n",
    "        \n",
    "        # Create subsets for this fold\n",
    "        train_sub = Subset(train_dataset, train_idx)\n",
    "        val_sub = Subset(train_dataset, val_idx)\n",
    "        \n",
    "        # Create DataLoader objects for the current fold\n",
    "        train_loader = DataLoader(train_sub, batch_size=32, shuffle=True, num_workers=4)\n",
    "        val_loader = DataLoader(val_sub, batch_size=32, shuffle=False, num_workers=4)\n",
    "        \n",
    "        # Initialize the model\n",
    "        model = PneumoniaDetectionCNN().to(device)\n",
    "        criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Training parameters\n",
    "        num_epochs = 25\n",
    "        best_fold_accuracy = 0.0\n",
    "        \n",
    "        # Training loop for the current fold\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "                \n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            train_losses.append(running_loss / len(train_loader))\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_losses[-1]:.4f}')\n",
    "            \n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "                    outputs = model(images)\n",
    "                    val_loss += criterion(outputs, labels).item()\n",
    "                    predicted = (outputs > 0.5).int()\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels.int()).sum().item()\n",
    "            \n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            val_accuracy = 100 * correct / total\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            print(f'Validation Loss: {val_losses[-1]:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "            \n",
    "            # Save the best model for this fold\n",
    "            if val_accuracy > best_fold_accuracy:\n",
    "                best_fold_accuracy = val_accuracy\n",
    "                torch.save(model.state_dict(), f'best_model_fold_{fold + 1}.pth')\n",
    "                print('Best model for this fold saved!')\n",
    "        \n",
    "        fold_accuracies.append(best_fold_accuracy)\n",
    "        fold_val_losses.append(min(val_losses))\n",
    "\n",
    "    # Calculate average results across all folds\n",
    "    average_accuracy = sum(fold_accuracies) / k_folds\n",
    "    average_val_loss = sum(fold_val_losses) / k_folds\n",
    "\n",
    "    print(f'\\nAverage Validation Accuracy across {k_folds} folds: {average_accuracy:.2f}%')\n",
    "    print(f'Average Validation Loss across {k_folds} folds: {average_val_loss:.4f}')\n",
    "\n",
    "    # Save overall results to a CSV file\n",
    "    with open('kfold_results.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['fold', 'val_accuracy', 'val_loss']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for fold in range(k_folds):\n",
    "            writer.writerow({'fold': fold + 1, 'val_accuracy': fold_accuracies[fold], 'val_loss': fold_val_losses[fold]})\n",
    "\n",
    "    print('K-Fold Cross-Validation complete and results saved.')\n",
    "\n",
    "# Direct function call for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_model(device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
